---
title: "ABDA Last"
author: "Zeynep Beyza Aktepe"
date: "2025-01-17"
output: html_document
---

```{r}
library(brms)
#library(tidyverse) 
```

```{r}
data <- read.csv("Student_performance_data.csv")
```

```{r}
head(data)
```

```{r}
colSums((data))
```

```{r}
# Convert GradeClass to an ordered factor
data$GradeClass <- factor(data$GradeClass, 
                                  levels = c(0, 1, 2, 3, 4), 
                                  labels = c("A", "B", "C", "D", "F"), 
                                  ordered = TRUE)
```

```{r}
# Standardize numeric predictors
data <- data %>%
  mutate(
    StudyTimeWeekly = scale(StudyTimeWeekly),
    Absences = scale(Absences)
  )
```

```{r}
# Check the structure of GradeClass
str(data$GradeClass)

# Confirm the levels and encoding
levels(data$GradeClass)
```

```{r}
head(data)
```

```{r}
# Check for missing values in the dataset
colSums(is.na(data))

# Summarize key variables
summary(data)

# Visualize the distribution of GradeClass
ggplot(data, aes(x = GradeClass)) +
  geom_bar() +
  labs(title = "Distribution of GradeClass", x = "Grade Class", y = "Count")

# Explore relationships between predictors and GradeClass
ggplot(data, aes(x = ParentalEducation, fill = GradeClass)) +
  geom_bar(position = "fill") +
  labs(title = "Parental Education vs Grade Class", x = "Parental Education", y = "Proportion") +
  theme_minimal()

```

```{r}
# Define improved priors
priors <- c(
  set_prior("normal(0, 2)", class = "b"),         # Stronger prior for fixed effects
  set_prior("cauchy(0, 2)", class = "sd"),        # Priors for random effect standard deviations
  set_prior("normal(0, 5)", class = "Intercept")  # Prior for intercepts
)

```



```{r}
# Explicitly use non-centered parameterization in brms
model <- brm(
  formula = GradeClass ~ Gender + ParentalEducation + StudyTimeWeekly + Absences + 
            Tutoring + ParentalSupport + Extracurricular + Sports + Music + Volunteering +
            (1 | Ethnicity),  # Random intercept for Ethnicity
  family = cumulative(link = "logit"),  # Ordinal logistic regression
  data = data,
  prior = priors,
  cores = 8,  # Parallel computation
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  backend = "cmdstanr"  # Use cmdstan backend for more efficient sampling
)

```

```{r}
# Print a summary of the model
summary(model)

# Plot diagnostics (trace plots and density plots)
plot(model)

# Posterior predictive checks
pp_check(model)

# Check the random effects for Ethnicity
ranef(model)

# Extract fixed effects
fixef(model)

```

```{r}
# Plot fixed effects with credible intervals
plot(conditional_effects(model), points = TRUE)

# Visualize the effect of StudyTimeWeekly on GradeClass
conditional_effects(model, effects = "StudyTimeWeekly") %>%
  plot()

# Visualize random effects (Ethnicity)
random_effects <- ranef(model)$Ethnicity
print(random_effects)

# Summarize and visualize posterior probabilities
posterior_samples <- posterior_samples(model)
head(posterior_samples)

```
#A positive estimate suggests that more absences increase the likelihood of being in lower grade classes (e.g., D or F) significantly.
#A negative estimate indicates that higher study time decreases the likelihood of lower grades (e.g., students are more likely to be in A or B).
#Higher parental support also decreases the likelihood of lower grades.

#STRONG PREDICTORS: Strong predictors include Absences, StudyTimeWeekly, Tutoring, ParentalSupport, Extracurricular, Sports, and Music based on their credible intervals (CIs not overlapping zero).

#WEAK PREDICTORS:Gender, ParentalEducation, and Volunteering have credible intervals that include zero, indicating weak or negligible effects. 
```{r}
pp_check(model, type = "hist")

```

```{r}
pp_check(model, type = "boxplot_grouped", group = "Ethnicity")

```


```{r}
mcmc_plot(model, type = "hist", bins = 30)

```


```{r}
mcmc_plot(model, type = "dens")
```

```{r}
pp_check(model, type = "ecdf_overlay")
#StudyTimeWeekly

```

```{r}
#'bars', 'bars_grouped', 'boxplot', 'dens', 'dens_overlay', 'dens_overlay_grouped', 'ecdf_overlay', 'ecdf_overlay_grouped', 'error_binned', 'error_hist', 'error_hist_grouped', 'error_scatter', 'error_scatter_avg', 'error_scatter_avg_grouped', 'error_scatter_avg_vs_x', 'freqpoly', 'freqpoly_grouped', 'hist', 'intervals', 'intervals_grouped', 'km_overlay', 'km_overlay_grouped', 'loo_intervals', 'loo_pit', 'loo_pit_overlay', 'loo_pit_qq', 'loo_ribbon', 'pit_ecdf', 'pit_ecdf_grouped', 'ribbon', 'ribbon_grouped', 'rootogram', 'scatter', 'scatter_avg', 'scatter_avg_grouped', 'stat', 'stat_2d', 'stat_freqpoly', 'stat_freqpoly_grouped', 'stat_grouped', 'violin_grouped'
#pp_check(model, type = "km_overlay")
conditional_effects(model, effects = 'Gender', 'ParentalEducation', 'StudyTimeWeekly', 'Absences', 'Tutoring'")
```


```{r}
pp_check(model, type = "stat", stat = "mean")

```
# The first plot compares the mean of the observed data (ð‘‡(ð‘¦), the vertical dark blue line) with the distribution of the means from the posterior predictive simulations (ð‘‡(ð‘¦rep), the histogram in light blue).

#Interpretation
#The observed mean (dark blue line) aligns very well with the simulated means from the posterior predictive distribution.
#This indicates that the model accurately captures the central tendency of the observed data.
#Assessment
#Good fit: There is no evidence of mismatch between the observed and predicted means.
#No improvement needed: The model fits the mean of the data well.

```{r}
pp_check(model, type = "stat", stat = "sd")

```

# The second plot compares the standard deviation of the observed data (ð‘‡(ð‘¦), the vertical dark blue line) with the distribution of the standard deviations from the posterior predictive simulations (ð‘‡(ð‘¦rep), the histogram in light blue).

#Interpretation
#The observed standard deviation (dark blue line) also aligns well with the simulated standard deviations.
#This suggests that the model captures the variability (spread) of the observed data effectively.
#Assessment
#Good fit: The predicted variability is consistent with the observed data.
#No improvement needed: The model adequately accounts for the spread in the data.


# Both checks indicate that:
#The model is doing a good job of capturing the mean and variability of the observed data.
#There is no evidence of systematic bias or misfit in these aspects of the data.

```{r}
# Plot random effects for Ethnicity
ranef_plot <- as.data.frame(ranef(model)$Ethnicity)
colnames(ranef_plot) <- c("Estimate", "Est.Error", "Q2.5", "Q97.5")
print(ranef_plot)

# Visualize random effects
library(ggplot2)
ggplot(ranef_plot, aes(x = rownames(ranef_plot), y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = Q2.5, ymax = Q97.5)) +
  labs(title = "Random Effects for Ethnicity", x = "Ethnicity", y = "Intercept Estimate") +
  theme_minimal()

```


```{r}
# Observed grade proportions
observed_grades <- table(data$GradeClass) / nrow(data)

# Predicted grade proportions
predicted_grades <- posterior_predict(model) %>%
  as.data.frame() %>%
  mutate_all(as.factor) %>%
  summarise_all(~ mean(. == levels(data$GradeClass))) %>%
  colMeans()

# Combine for comparison
grade_comparison <- data.frame(
  Grade = levels(data$GradeClass),
  Observed = observed_grades,
  Predicted = predicted_grades
)

# Plot comparison
ggplot(grade_comparison, aes(x = Grade)) +
  geom_bar(aes(y = Observed, fill = "Observed"), stat = "identity", position = "dodge") +
  geom_bar(aes(y = Predicted, fill = "Predicted"), stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Observed" = "blue", "Predicted" = "red")) +
  labs(title = "Observed vs Predicted Grade Proportions", y = "Proportion") +
  theme_minimal()

```
```{r}
# Compute LOO cross-validation
loo_result <- loo(model)

# Plot diagnostic for influential points
plot(loo_result)

```
#Most k-values are well below 0.5, indicating that the majority of observations are not overly influential and the model is robust for these data points.
#here are no visible points exceeding ð‘˜â‰¥1, meaning there are no extremely problematic observations that could destabilize the model.
#The distribution of k-values is relatively uniform and centered around k=0, which suggests the model is fitting well overall.

#The model appears to perform well in terms of LOO cross-validation diagnostics, with no major concerns about individual observations.

```{r}
pp_check(model, type = "stat", stat = "skewness")

```

```{r}
pp_check(model, type = "bars", prob = 0.5)

```


```{r}
pp_check(model, type = "stat_grouped", stat = "mean", group = "Ethnicity")

```
```{r}
pp_check(model, type = "violin_grouped", group = "Ethnicity")

```

```{r}
######## NICE TO HAVE STUFF START ###########
posterior_samples(model_with_default_priors) %>%
  bind_rows(posterior_samples(model_with_new_priors), .id = "Model") %>%
  ggplot(aes(x = parameter, y = value, fill = Model)) +
  geom_density_ridges()

######## NICE TO HAVE STUFF END ###########
```


#To do
#Other predictors like Gender, Extracurricular, Sports, and Music have smaller effects with credible intervals that include zero, suggesting weak or negligible influence.
#The standard deviation of the random intercept is small, indicating limited variability in GradeClass across Ethnic groups after accounting for fixed effects.
##The random intercept for Ethnicity (with near-zero estimates and small standard deviations) suggests it contributes little. Consider alternative groupings (e.g., ParentalSupport, AbsenceLevel) to capture more meaningful group-level variability.
##Exchangeability within Ethnicity: Suggestion of chatgpt is to Replace Ethnicity with a more meaningful grouping (e.g., ParentalEducation or ParentalSupport).
## enhancing exchagability (1 | ParentalSupport) or (1 | StudyTimeCategory)
##OR 
#Adding Group-Level Predictors:
#Include predictors like group-level mean Absences or mean StudyTimeWeekly to better explain between-group differences:
#GradeClass ~ GroupLevelMeanAbsences + ... + (1 | Group)



###### IS THERE INDEPENDENCE? HOW TO CHECK
##Ordinal logistic regression assumes proportional odds, meaning the relationship between predictors and the log odds of being in a higher category is constant across categories (e.g., the effect of Absences is the same for A vs B as it is for D vs F).
##Test Proportional Odds Assumption:
##Use the brant test or polr function from the MASS package in simpler models to check proportional odds:
library(MASS)
polr_model <- polr(GradeClass ~ Absences + StudyTimeWeekly + ..., data = data)
summary(polr_model)
brant(polr_model)

#If the assumption is violated: Consider a partial proportional odds model or multinomial logistic regression (if ordinal structure is weak).



###Consider Interaction Terms: GradeClass ~ ParentalSupport * ParentalEducation + ...

#how did we do feature selection?
#exchangability ~ if they're apriori exchangeable
#also nice, prior sensitivity analysis
