---
title: "Refined_1"
author: "HamzaAfzalAshraf"
date: "2025-01-19"
output: pdf_document
---

```{r}
## Install the 'cmdstanr' package from GitHub
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))

## Check if the package was installed successfully
#library(cmdstanr)

# Install CmdStan (if not already installed)
#cmdstanr::install_cmdstan()

#cmdstanr::check_cmdstan_toolchain(fix = TRUE)
#cmdstanr::check_cmdstan_toolchain()
#cmdstanr::install_cmdstan()
library(brms)
```

## Flat model first.
```{r}

data <- read.csv("Student_performance_data.csv")
# Convert GradeClass to an ordered factor
data$GradeClass <- factor(data$GradeClass, 
                                  levels = c(0, 1, 2, 3, 4), 
                                  labels = c("A", "B", "C", "D", "F"), 
                                  ordered = TRUE)
# Check the structure of GradeClass
str(data$GradeClass)

# Confirm the levels and encoding
levels(data$GradeClass)
head(data)
```


```{r}
# Check for missing values in the dataset
colSums(is.na(data))

# Summarize key variables
summary(data)

# Visualize the distribution of GradeClass
ggplot(data, aes(x = GradeClass)) +
  geom_bar() +
  labs(title = "Distribution of GradeClass", x = "Grade Class", y = "Count")

# Explore relationships between predictors and GradeClass
ggplot(data, aes(x = ParentalEducation, fill = GradeClass)) +
  geom_bar(position = "fill") +
  labs(title = "Parental Education vs Grade Class", x = "Parental Education", y = "Proportion") +
  theme_minimal()


# Explore relationships between predictors and GradeClass
ggplot(data, aes(x = Ethnicity, fill = GradeClass)) +
  geom_bar(position = "fill") +
  labs(title = "Ethnicity vs Grade Class", x = "Ethnicity", y = "Proportion") +
  theme_minimal()

```


```{r}
# Standardize numeric predictors
data <- data %>%
  mutate(
    StudyTimeWeekly = scale(StudyTimeWeekly),
    Absences = scale(Absences)
  )
```


```{r}
# Define improved priors
priors <- c(
  set_prior("normal(0, 2)", class = "b"),         # Stronger prior for fixed effects
  set_prior("normal(0, 5)", class = "Intercept")  # Prior for intercepts
)
```


```{r}
flat_model <- brm(
  formula = GradeClass ~ Gender + ParentalEducation + StudyTimeWeekly + Absences + 
            Tutoring + ParentalSupport + Extracurricular + Sports + Music + Volunteering + Ethnicity,
  
  family = cumulative(link = "logit"),  # Ordinal logistic regression
  data = data,
  prior = priors,
  cores = 8,  # Parallel computation
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.999, max_treedepth = 20),
  backend = "cmdstanr"  # Use cmdstan backend for more efficient sampling
)

```



```{r}
summary(flat_model)
```
overlapping zero predictors considered non-significant

## Base Line FORMULA: formula = GradeClass ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + Extracurricular + Sports + Music + (1 | Level)

```{r}
# Extract fixed effects summary
flat_model_summary <- summary(flat_model)

# Convert fixed effects summary into a data frame
flat_model_effects <- as.data.frame(flat_model_summary$fixed)

# Add a logical column to flag important predictors
flat_model_effects <- flat_model_effects %>%
  mutate(
    Important = !(Estimate - 1.96 * Est.Error < 0 & Estimate + 1.96 * Est.Error > 0)  # CI excludes zero
  )

# Filter for important predictors
important_predictors <- flat_model_effects %>%
  filter(Important == TRUE)
print(important_predictors)

```

#Model for Study group
```{r}

data <- read.csv("Student_performance_data.csv")# Standardize numeric predictors

# Convert GradeClass to an ordered factor
data$GradeClass <- factor(data$GradeClass, 
                                  levels = c(0, 1, 2, 3, 4), 
                                  labels = c("A", "B", "C", "D", "F"), 
                                  ordered = TRUE)
```

```{r}
# Standardizing the Study Habits variables
data <- data %>%
  mutate(
    StudyTimeWeekly_scaled = scale(StudyTimeWeekly),
    Absences_scaled = scale(Absences),
    Tutoring_scaled = scale(Tutoring)
  )
# Creating a composite variable for Study Habits
data <- data %>%
  mutate(
    StudyHabits = StudyTimeWeekly_scaled + Absences_scaled + Tutoring_scaled
  )

# Grouping StudyHabits into categories
data <- data %>%
  mutate(
    StudyHabitsGroup = case_when(
      StudyHabits <= -1.5 ~ "Low",
      StudyHabits > -1.5 & StudyHabits <= 1.5 ~ "Medium",
      StudyHabits > 1.5 ~ "High"
    )
  )


priors <- c(
  set_prior("normal(0, 2)", class = "b"),          # Prior for fixed effects (StudyTimeWeekly, etc.)
  set_prior("normal(0, 5)", class = "Intercept"),  # Prior for intercepts
  set_prior("normal(0, 2)", class = "sd")         # Prior for random effects (Ethnicity)
)
# Fit the hierarchical model
hierarchical_model_studyhabbits <- brm(
  formula = GradeClass ~ ParentalSupport + Extracurricular + Sports + Music + Volunteering + (1 | StudyHabitsGroup),


  family = cumulative(link = "logit"),  # Ordinal logistic regression
  data = data,
  prior = priors,
  cores = 8, 
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.999, max_treedepth = 20),
  backend = "cmdstanr"  
)
summary(hierarchical_model_studyhabbits)

```

```{r}
summary(hierarchical_model_studyhabbits)
```


# Model for Activity group
```{r}
data <- read.csv("Student_performance_data.csv")# Standardize numeric predictors
data <- data %>%
  mutate(
    StudyTimeWeekly = scale(StudyTimeWeekly),
    Absences = scale(Absences)
  )
# Convert GradeClass to an ordered factor
data$GradeClass <- factor(data$GradeClass, 
                                  levels = c(0, 1, 2, 3, 4), 
                                  labels = c("A", "B", "C", "D", "F"), 
                                  ordered = TRUE)
```

```{r}

# Create a grouping variable for extracurricular activities
data <- data %>%
  mutate(
    ActivityGroup = case_when(
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Activities",
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 0 ~ "All Except Volunteering",
      Extracurricular == 1 & Sports == 0 & Music == 1 & Volunteering == 1 ~ "All Except Sports",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "All Except Music",
      Extracurricular == 0 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Except Extracurricular",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "Only Extracurricular",
      Extracurricular == 0 & Sports == 1 & Music == 0 & Volunteering == 0 ~ "Only Sports",
      Extracurricular == 0 & Sports == 0 & Music == 1 & Volunteering == 0 ~ "Only Music",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "Only Volunteering",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "No Activities",
      TRUE ~ "Other"
    )
  )
# Define priors
priors <- c(
  set_prior("normal(0, 2)", class = "b"),           # Prior for fixed effects
  set_prior("normal(0, 5)", class = "Intercept"),   # Prior for intercepts
  set_prior("normal(0, 2)", class = "sd")           # Prior for random effects (ActivityGroup)
)

# Fit the hierarchical model with ActivityGroup as random effect
hierarchical_model <- brm(
  formula = GradeClass ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + (1 | ActivityGroup), 
  family = cumulative(link = "logit"),  # Ordinal logistic regression
  data = data,
  prior = priors,
  cores = 8, 
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.999, max_treedepth = 20),
  backend = "cmdstanr"  
)

```


```{r}
summary(hierarchical_model)
```

```{r}
# Compare models using WAIC
waic_model1 <- waic(hierarchical_model_studyhabbits)
waic_model2 <- waic(hierarchical_model)

# Display WAIC for both models
waic_model1
waic_model2

```


```{r}
loo_result1 <- loo(hierarchical_model_studyhabbits)
loo_result2 <- loo(hierarchical_model)

loo_result1
loo_result2
```




```{r}
pp_check(hierarchical_model_studyhabbits, type = "bars")
pp_check(hierarchical_model, type = "bars")

```

```{r}
pp_check(hierarchical_model_studyhabbits)
pp_check(hierarchical_model)
```


```{r}
plot(conditional_effects(hierarchical_model_studyhabbits), points = TRUE)
```


```{r}
# Plot marginal effects of significant predictors
marginal_effects(hierarchical_model)

# Generate posterior predictive check plots
pp_check(hierarchical_model, type = "dens_overlay")
pp_check(hierarchical_model, type = "hist")

# Conditional effects to show relationships
#conditional_effects(hierarchical_model, effects = "StudyTimeWeekly:Absences")

```

```{r}
plot(conditional_effects(hierarchical_model), points = TRUE)
```




# For continuous model
```{r}
# Read in your dataset
student_data <- read.csv("Student_performance_data.csv")
student_data <- student_data %>%
  mutate(
    ActivityGroup = case_when(
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Activities",
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 0 ~ "All Except Volunteering",
      Extracurricular == 1 & Sports == 0 & Music == 1 & Volunteering == 1 ~ "All Except Sports",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "All Except Music",
      Extracurricular == 0 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Except Extracurricular",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "Only Extracurricular",
      Extracurricular == 0 & Sports == 1 & Music == 0 & Volunteering == 0 ~ "Only Sports",
      Extracurricular == 0 & Sports == 0 & Music == 1 & Volunteering == 0 ~ "Only Music",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "Only Volunteering",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "No Activities",
      TRUE ~ "Other"
    )
  )
# Scale continuous predictors
student_data$StudyTimeWeekly_z <- scale(student_data$StudyTimeWeekly)
student_data$Absences_z <- scale(student_data$Absences)

formula = GPA ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + (1 | ActivityGroup)

priors <- c(
  prior(normal(0, 0.5), class = "b"),                     # Stronger prior for regression coefficients
  prior(student_t(3, 0, 2), class = "Intercept")          # Narrower prior for intercepts
)


# Fit the Bayesian hierarchical model using Gaussian family for continuous GPA
model_continuous <- brm(
  formula = formula,
  family = "gaussian",   # Gaussian family for continuous outcome
  data = student_data,
  prior = priors,
  cores= 8,
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.999, max_treedepth = 20),
  backend = "cmdstanr"
)

# Print a summary of the model
summary(model_continuous)

```

```{r}

loo_model1 <- loo(model_continuous)              # For Model #1
loo_model2 <- loo(hierarchical_model)            # For Model #2
print(loo_model1)
print(loo_model2)

#loo_compare(loo(model), loo(model_continuous))

```
```{r}
plot(conditional_effects(model_continuous), points = TRUE)
```

```{r}
pp_check(model_continuous, type = "error_scatter_avg")
```


```{r}

pp_check(model_continuous, type = "dens_overlay")
```




```{r}
predictions <- posterior_predict(model)
pred_classes <- apply(predictions, 2, function(x) which.max(table(x)))
accuracy <- mean(pred_classes == as.numeric(data$GradeClass))

pp_check(model, type = "bars")

```


```{r}
predictions <- posterior_predict(model_continuous)
mse <- mean((data$GPA - colMeans(predictions))^2)
bayes_R2(model_continuous)
pp_check(model_continuous, type = "dens_overlay")
```


### Prior Sensitivity Analysis ###

```{r}
data <- read.csv("Student_performance_data.csv")# Standardize numeric predictors

# Create a grouping variable for extracurricular activities
data <- data %>%
  mutate(
    ActivityGroup = case_when(
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Activities",
      Extracurricular == 1 & Sports == 1 & Music == 1 & Volunteering == 0 ~ "All Except Volunteering",
      Extracurricular == 1 & Sports == 0 & Music == 1 & Volunteering == 1 ~ "All Except Sports",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "All Except Music",
      Extracurricular == 0 & Sports == 1 & Music == 1 & Volunteering == 1 ~ "All Except Extracurricular",
      Extracurricular == 1 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "Only Extracurricular",
      Extracurricular == 0 & Sports == 1 & Music == 0 & Volunteering == 0 ~ "Only Sports",
      Extracurricular == 0 & Sports == 0 & Music == 1 & Volunteering == 0 ~ "Only Music",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 1 ~ "Only Volunteering",
      Extracurricular == 0 & Sports == 0 & Music == 0 & Volunteering == 0 ~ "No Activities",
      TRUE ~ "Other"
    )
  )

data <- data %>%
  mutate(
    StudyTimeWeekly = scale(StudyTimeWeekly),
    Absences = scale(Absences)
  )
# Convert GradeClass to an ordered factor
data$GradeClass <- factor(data$GradeClass, 
                                  levels = c(0, 1, 2, 3, 4), 
                                  labels = c("A", "B", "C", "D", "F"), 
                                  ordered = TRUE)

```


1. Define a Set of Alternative Priors
```{r}
priors_alt1 <- c(
  set_prior("normal(0, 1)", class = "b"),  # Narrower prior for regression coefficients
  set_prior("cauchy(0, 1)", class = "sd"),  # Tighter prior for random effects
  set_prior("student_t(3, 0, 2)", class = "Intercept")  # Informative prior for intercepts
)

priors_alt2 <- c(
  set_prior("normal(0, 10)", class = "b"),  # Weakly informative priors
  set_prior("cauchy(0, 5)", class = "sd"),  # Broader prior for random effects
  set_prior("normal(0, 10)", class = "Intercept")  # Weakly informative prior for intercepts
)

```

2. Refit the Model with Alternative Priors
```{r}
# Model with alternative priors (tight priors)
model_alt1 <- brm(
  formula = GradeClass ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + (1 | ActivityGroup),
  family = cumulative(link = "logit"),
  data = data,
  prior = priors_alt1,
  cores= 8,
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
)

# Model with alternative priors (weak priors)
model_alt2 <- brm(
  formula = GradeClass ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + (1 | ActivityGroup),
  family = cumulative(link = "logit"),
  data = data,
  prior = priors_alt2,
  cores= 8,
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
)

```


3. Compare Posterior Estimates
Visual Comparison:
```{r}
# Extract posterior samples for the original and alternative models
posterior_original <- posterior_samples(model)
posterior_alt1 <- posterior_samples(model_alt1)
posterior_alt2 <- posterior_samples(model_alt2)

# Combine into a single data frame
posterior_combined <- bind_rows(
  posterior_original %>% mutate(Model = "Original"),
  posterior_alt1 %>% mutate(Model = "Alt1"),
  posterior_alt2 %>% mutate(Model = "Alt2")
)

# Plot density ridges for a parameter (e.g., "b_Absences")
library(ggridges)
ggplot(posterior_combined, aes(x = b_Absences, y = Model, fill = Model)) +
  geom_density_ridges(alpha = 0.5) +
  labs(title = "Prior Sensitivity Analysis: Effect of Absences",
       x = "Posterior Estimate (Absences)", y = "Model") +
  theme_minimal()

```

Numerical Comparison:
```{r}
# Summarize posterior estimates for key parameters
summary_original <- summary(model)$fixed
summary_alt1 <- summary(model_alt1)$fixed
summary_alt2 <- summary(model_alt2)$fixed

# Combine into a table for comparison
sensitivity_results <- bind_rows(
  Original = summary_original,
  Alt1 = summary_alt1,
  Alt2 = summary_alt2,
  .id = "Model"
)

# Print the table
print(sensitivity_results)

```

4. Evaluate Model Fit
Posterior Predictive Checks:
```{r}
# Original model
pp_check(model, type = "dens_overlay")

# Alternative models
pp_check(model_alt1, type = "dens_overlay")
pp_check(model_alt2, type = "dens_overlay")

```

Model Fit Comparison:
```{r}
# Compare WAIC or LOO
loo_original <- loo(hierarchical_model)
loo_alt1 <- loo(model_alt1)
loo_alt2 <- loo(model_alt2)

# Compare results
loo_compare(loo_original, loo_alt1, loo_alt2)

```

Interpreting the Results

Robustness:
- If the posterior distributions and model performance metrics (e.g., LOO, WAIC) remain consistent across different priors, your results are robust.
- If they change significantly, your results are sensitive to prior assumptions.

Improvement:
- Use the priors that yield better fit (lower WAIC or higher LOO-ELPD).
- Adjust the priors further based on domain knowledge or data characteristics.

```{r}
# Refined Model with Increased Stability
model_final <- brm(
  GradeClass ~ formula = GradeClass ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport + (1 | ActivityGroup),
  family = cumulative(link = "logit"),
  data = data,
  prior = priors_alt2,  # Use weakly informative priors for robustness
  iter = 4000, warmup = 2000, chains = 4, seed = 123,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
)

# Posterior Predictive Check
pp_check(model_final)

# LOO Cross-Validation
loo_final <- loo(model_final)
print(loo_final)

```

